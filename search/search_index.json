{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This is a full-stack machine learning project. It includes the following: Multiple Flask apps Model training script Tests GitHub workflow for automatic testing A good project organization! Documentation Good dependency management. We are using pip-tools but other managers also work. Automatic deployments to AWS SageMaker and saving the models to S3 Exercises of each day Day 1 Start a new and empty GitHub repository. Think about how you're going to organize your project. What folders will it have? What files will go into this folders? Start writing documentation about your project. You will need to keep it updated throughout the week. The instructions provided are for MkDocs, but you can use other documentation methods if you want. Write a script to train an ML model. Turn the 2.train.ipynb notebook into a python script The script can have the following options: --download-data --train --epochs INT (it should have a default) --optimizer STRING --load-weights STRING # extra work: # load the data URL from an environment variable (using a .env file and the python-dotenv package) Then you can run the script like: python3 train.py --download-data --train --epochs 3 --optimizer sgd --load-weights my_weigths.pth Don't worry if you can't implement all the options Day 1.2 Try creating a Python class that abstracts all the operations you want to make that interact with the database. class DB: def __init__(self, dbname): self.conn = sqlite3.connect(dbname) def do_something(self): with self.conn as cursor: cursor.execute(\".......\", (a, b)) Day 2 Understand this github repository. why it's organized like that, how is the documentation written (using the mkdocs library we sa), and more importantly, understanding the service.py file. That file is a Flask application, last week you used flask to show some HTML, this week we are using it to receive an image and doing a prediction with it. Create an HTML form using flask. An HTML form is the same thing you fill in when signing up in a new website. The task is creating an HTML form that lets the user upload an image. Here's some info on how to do it, but feel free to look for other resources. You can try doing everything inside service.py if that's easier at first. So both the file upload and model prediction is donde in the same place. Feel free to adapt the exercise. After that's done, try to integrate this HTML form with service.py , now when you receive an image, instead of doing nothing with it, use the requests library to send it to the other service. As always, having everything done is not the objective. The objective is that you understand how to design a solution to a problem and how to communicate and organize the \"solution\" (our project). If you have time you can work on the documentation and improve it. Explain to other people how to run your service.py and/or app.py. Video Logging inside a Flask app Day 3 Create an HTML form to register a new user (email + password) Save the password hashed to the DB Finish writing the test in the tests/test_app.py file Add some more tests, even if they are simple ones Extra: * If you have problems with passlib. I will now create an alternative secure hashing function and update the file. It will take me 10 or 15 minutes. Also, always take into account that hashing functions receive and return bytes, not strings. Passlib already handles that for you, but if you look at my implementation you'll see that I'm doing a few password.encode() to convert a string to bytes and hash(...).hex() to convert the hashed bytes to an hexadecimal string if you are already receiving bytes you don't need to encode it, but when you get the data from the flask request i'm pretty sure it's as a string, not bytes. ANyway, if you don't get the hashing working 100% don't worry, you can \"create\" your own hashing by just appending a random string to the end. As long as you make it work and write a couple of tests. Something extra to try in the exercises: Creating a test for the ML model (taking the functions from service.py). For example, testing that the function returns one of the 2 classes. Or that if you have an image that it's been correctly predicted, write a test for it. Day 4 Create a github workflow that does anything. It can be just a print() or running all the tests. You can do it in a new empty repository or in an old one. Some resources that may be helpful: Official introduction to GitHub Actions GitHub Actios Syntax (this is a long one, you don't really need it for now) A basic template for a github action. It does a print(\"hello\") with Python Remember, the workflows/actions have to be inside a folder called .github/workflows inside your repo. Final So far we have learned how to deal with Flask apps running ML models, Python scripts to train models, how to organize a project or how to write documentation . Now imagine your ML product has do more things. Your users may be sending you some unwanted data and you need to filter it. Well, the best way to do it is with another model. The task for the last day is: Getting a new dataset with items that are not part of your main dataset. Train a yes/no model. The model should be able to filter data that does not belong to your dataset. Deploy this model as a new Flask app. When a new item arrives, it first goes through the first Flask app / service. If it determines it belongs to your data, then send the item to the main Flask service. Some things you may modify: Instead of running the image through the 2 flask apps, you can implement an HTML dropdown / form field to let the user choose which model they want to run the image through. Instead of running the 2 ML models in different Flask apps, you can try putting the 2 models insider service.py. This is a double-edged sword. It's easier because you don't need to run an extra Flask app. However, now you need to load 2 models inside a single Flask app, which may also become a challenge.","title":"Introduction"},{"location":"#exercises-of-each-day","text":"","title":"Exercises of each day"},{"location":"#day-1","text":"Start a new and empty GitHub repository. Think about how you're going to organize your project. What folders will it have? What files will go into this folders? Start writing documentation about your project. You will need to keep it updated throughout the week. The instructions provided are for MkDocs, but you can use other documentation methods if you want. Write a script to train an ML model. Turn the 2.train.ipynb notebook into a python script The script can have the following options: --download-data --train --epochs INT (it should have a default) --optimizer STRING --load-weights STRING # extra work: # load the data URL from an environment variable (using a .env file and the python-dotenv package) Then you can run the script like: python3 train.py --download-data --train --epochs 3 --optimizer sgd --load-weights my_weigths.pth Don't worry if you can't implement all the options","title":"Day 1"},{"location":"#day-12","text":"Try creating a Python class that abstracts all the operations you want to make that interact with the database. class DB: def __init__(self, dbname): self.conn = sqlite3.connect(dbname) def do_something(self): with self.conn as cursor: cursor.execute(\".......\", (a, b))","title":"Day 1.2"},{"location":"#day-2","text":"Understand this github repository. why it's organized like that, how is the documentation written (using the mkdocs library we sa), and more importantly, understanding the service.py file. That file is a Flask application, last week you used flask to show some HTML, this week we are using it to receive an image and doing a prediction with it. Create an HTML form using flask. An HTML form is the same thing you fill in when signing up in a new website. The task is creating an HTML form that lets the user upload an image. Here's some info on how to do it, but feel free to look for other resources. You can try doing everything inside service.py if that's easier at first. So both the file upload and model prediction is donde in the same place. Feel free to adapt the exercise. After that's done, try to integrate this HTML form with service.py , now when you receive an image, instead of doing nothing with it, use the requests library to send it to the other service. As always, having everything done is not the objective. The objective is that you understand how to design a solution to a problem and how to communicate and organize the \"solution\" (our project). If you have time you can work on the documentation and improve it. Explain to other people how to run your service.py and/or app.py. Video Logging inside a Flask app","title":"Day 2"},{"location":"#day-3","text":"Create an HTML form to register a new user (email + password) Save the password hashed to the DB Finish writing the test in the tests/test_app.py file Add some more tests, even if they are simple ones Extra: * If you have problems with passlib. I will now create an alternative secure hashing function and update the file. It will take me 10 or 15 minutes. Also, always take into account that hashing functions receive and return bytes, not strings. Passlib already handles that for you, but if you look at my implementation you'll see that I'm doing a few password.encode() to convert a string to bytes and hash(...).hex() to convert the hashed bytes to an hexadecimal string if you are already receiving bytes you don't need to encode it, but when you get the data from the flask request i'm pretty sure it's as a string, not bytes. ANyway, if you don't get the hashing working 100% don't worry, you can \"create\" your own hashing by just appending a random string to the end. As long as you make it work and write a couple of tests. Something extra to try in the exercises: Creating a test for the ML model (taking the functions from service.py). For example, testing that the function returns one of the 2 classes. Or that if you have an image that it's been correctly predicted, write a test for it.","title":"Day 3"},{"location":"#day-4","text":"Create a github workflow that does anything. It can be just a print() or running all the tests. You can do it in a new empty repository or in an old one. Some resources that may be helpful: Official introduction to GitHub Actions GitHub Actios Syntax (this is a long one, you don't really need it for now) A basic template for a github action. It does a print(\"hello\") with Python Remember, the workflows/actions have to be inside a folder called .github/workflows inside your repo.","title":"Day 4"},{"location":"#final","text":"So far we have learned how to deal with Flask apps running ML models, Python scripts to train models, how to organize a project or how to write documentation . Now imagine your ML product has do more things. Your users may be sending you some unwanted data and you need to filter it. Well, the best way to do it is with another model. The task for the last day is: Getting a new dataset with items that are not part of your main dataset. Train a yes/no model. The model should be able to filter data that does not belong to your dataset. Deploy this model as a new Flask app. When a new item arrives, it first goes through the first Flask app / service. If it determines it belongs to your data, then send the item to the main Flask service. Some things you may modify: Instead of running the image through the 2 flask apps, you can implement an HTML dropdown / form field to let the user choose which model they want to run the image through. Instead of running the 2 ML models in different Flask apps, you can try putting the 2 models insider service.py. This is a double-edged sword. It's easier because you don't need to run an extra Flask app. However, now you need to load 2 models inside a single Flask app, which may also become a challenge.","title":"Final"},{"location":"dependency_management/","text":"Python packages and dependencies We can use pip-tools to take a file with requirements and get a new one with the versions pinned. Pinned = with a very specific version number associated pip-compile -v --output-file requirements/main.txt requirements/main.in pip-compile -v --output-file requirements/dev.txt requirements/dev.in To upgrade: pip-compile -v --upgrade --output-file requirements/main.txt requirements/main.in pip-compile -v --upgrade --output-file requirements/dev.txt requirements/dev.in To replicate an environment: pip-sync requirements/*.txt","title":"Python packages and dependencies"},{"location":"dependency_management/#python-packages-and-dependencies","text":"We can use pip-tools to take a file with requirements and get a new one with the versions pinned. Pinned = with a very specific version number associated pip-compile -v --output-file requirements/main.txt requirements/main.in pip-compile -v --output-file requirements/dev.txt requirements/dev.in To upgrade: pip-compile -v --upgrade --output-file requirements/main.txt requirements/main.in pip-compile -v --upgrade --output-file requirements/dev.txt requirements/dev.in To replicate an environment: pip-sync requirements/*.txt","title":"Python packages and dependencies"},{"location":"documentation/","text":"MkDocs The documentation of this project is built using mkdocs with the mkdocs-material theme. For full documentation visit mkdocs.org . pip install mkdocs mkdocs-material Basic commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Now run: mkdocs new documentation_page cd documentation_page Edit the mkdocs.yaml file. theme: name: material language: en plugins: - search nav: - Introduction: 'index.md' - Examples: 'examples.md' - Models: 'models.md' Development: mkdocs serve Inside your documentation_page/docs folder, you can create an examples.md and models.md files and they will show up in your mkdocs site! Production: mkdocs build That's it! This will generate a site/ folder. Updating the documentation Modify any of the markdown files and from the documentation_page/ folder run: mkdocs gh-deploy This will automatically build the docs and push them to the gh-pages branch. Do not modify the files directly in the github branch . GitHub will detect the branch and build a static documentation site for the project. NOTE Make sure to keep the mkdocs.yaml configuration file updated if you create new files.","title":"Documentation"},{"location":"documentation/#mkdocs","text":"The documentation of this project is built using mkdocs with the mkdocs-material theme. For full documentation visit mkdocs.org . pip install mkdocs mkdocs-material","title":"MkDocs"},{"location":"documentation/#basic-commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Now run: mkdocs new documentation_page cd documentation_page Edit the mkdocs.yaml file. theme: name: material language: en plugins: - search nav: - Introduction: 'index.md' - Examples: 'examples.md' - Models: 'models.md' Development: mkdocs serve Inside your documentation_page/docs folder, you can create an examples.md and models.md files and they will show up in your mkdocs site! Production: mkdocs build That's it! This will generate a site/ folder.","title":"Basic commands"},{"location":"documentation/#updating-the-documentation","text":"Modify any of the markdown files and from the documentation_page/ folder run: mkdocs gh-deploy This will automatically build the docs and push them to the gh-pages branch. Do not modify the files directly in the github branch . GitHub will detect the branch and build a static documentation site for the project. NOTE Make sure to keep the mkdocs.yaml configuration file updated if you create new files.","title":"Updating the documentation"},{"location":"models/","text":"Model description This model is a binar classifier. It will classify between ants and bees . The training data includes 10 images of each class for training and 2 images of each class for validation #bigdata. Jokes apart, this is done on purpose to make it easier to experiment. Once you feel confortable with your workflow, you can try with bigger datasets. Remeber to change the model if you need to! (mostly the last fully-connected layer) Remember to always start with good baselines For example. In computer vision a resnet18 is a good starting point. In text classification an LSTM may be a good starting point.","title":"Models"},{"location":"models/#model-description","text":"This model is a binar classifier. It will classify between ants and bees . The training data includes 10 images of each class for training and 2 images of each class for validation #bigdata. Jokes apart, this is done on purpose to make it easier to experiment. Once you feel confortable with your workflow, you can try with bigger datasets. Remeber to change the model if you need to! (mostly the last fully-connected layer)","title":"Model description"},{"location":"models/#remember-to-always-start-with-good-baselines","text":"For example. In computer vision a resnet18 is a good starting point. In text classification an LSTM may be a good starting point.","title":"Remember to always start with good baselines"},{"location":"running/","text":"How to run the model as a separate service This app is designed to be run inside Flask. The machine learning model is running in service.py . The main app is inside app.py . If you run any of the apps in a different port, check the python files and modify them accordingly. To run the apps use: FLASK_ENV=development FLASK_APP=service.py flask run --port 5005 FLASK_ENV=development FLASK_APP=app.py flask run --port 5002 Now you can navigate to 127.0.0.1:5002 and use your app. The main app.py calls service.py to do the predictions. At the top fo the Flask apps there are a few configuration variables. They are mostly about the paths to find the files we need and the name of the files (for example the weights of the best performing model). Modify those if you change the project structure.","title":"Running the apps"},{"location":"running/#how-to-run-the-model-as-a-separate-service","text":"This app is designed to be run inside Flask. The machine learning model is running in service.py . The main app is inside app.py . If you run any of the apps in a different port, check the python files and modify them accordingly. To run the apps use: FLASK_ENV=development FLASK_APP=service.py flask run --port 5005 FLASK_ENV=development FLASK_APP=app.py flask run --port 5002 Now you can navigate to 127.0.0.1:5002 and use your app. The main app.py calls service.py to do the predictions. At the top fo the Flask apps there are a few configuration variables. They are mostly about the paths to find the files we need and the name of the files (for example the weights of the best performing model). Modify those if you change the project structure.","title":"How to run the model as a separate service"},{"location":"training/","text":"Here's an example to train a new model. In order to run the training script use: python3 train.py --download-data python3 train.py --train --epochs 2 --optmizer adam When the training finishes, the best model weights will be saved to a file called best_model.pth . NOTE : The train.py script is still missing some features. Feel free to implement them: Choosing the folder to save the downloaded data Choosing the name and folder to save the best model Whatever comes to your mind!","title":"Training"}]}